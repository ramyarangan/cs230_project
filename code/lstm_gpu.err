/home/users/ramyar/.bashrc: line 33: bind: warning: line editing not enabled
[?1034h/home/users/ramyar/.bashrc: line 34: bind: warning: line editing not enabled

The following have been reloaded with a version change:
  1) python/3.6.1 => python/2.7.13


The following have been reloaded with a version change:
  1) python/2.7.13 => python/3.6.1


The following have been reloaded with a version change:
  1) cuda/11.2.0 => cuda/11.1.1         3) ucx/1.10.0 => ucx/1.9.0
  2) openmpi/4.1.0 => openmpi/4.0.5


The following have been reloaded with a version change:
  1) cuda/11.1.1 => cuda/11.2.0         3) ucx/1.9.0 => ucx/1.10.0
  2) openmpi/4.0.5 => openmpi/4.1.0

/var/spool/slurmd/job25415477/slurm_script: line 42: /scratch/users/ramyar/cs230/cs230_project/code/cs230_venv/bin/activate: No such file or directory
2021-05-29 13:28:08.625495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
wandb: Currently logged in as: ramyarangan (use `wandb login --relogin` to force relogin)
2021-05-29 13:28:34.313108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
wandb: Tracking run with wandb version 0.10.31
wandb: Syncing run cerulean-bush-5
wandb: ⭐️ View project at https://wandb.ai/ramyarangan/splicing
wandb: 🚀 View run at https://wandb.ai/ramyarangan/splicing/runs/12j70w8e
wandb: Run data is saved locally in /scratch/users/ramyar/cs230/cs230_project/code/wandb/run-20210529_132832-12j70w8e
wandb: Run `wandb offline` to turn off syncing.
2021-05-29 13:28:37.386801: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-29 13:28:37.389739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-05-29 13:28:37.422956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:c4:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-05-29 13:28:37.423010: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-29 13:28:37.431633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-29 13:28:37.431682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-29 13:28:37.436589: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-05-29 13:28:37.439401: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-05-29 13:28:37.449520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-05-29 13:28:37.453523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-05-29 13:28:37.456205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-05-29 13:28:37.458704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-05-29 13:28:37.459303: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-05-29 13:28:37.459862: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-29 13:28:37.461119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:c4:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-05-29 13:28:37.461166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-29 13:28:37.461188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-29 13:28:37.461208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-29 13:28:37.461226: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-05-29 13:28:37.461245: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-05-29 13:28:37.461263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-05-29 13:28:37.461281: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-05-29 13:28:37.461300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-05-29 13:28:37.463635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-05-29 13:28:37.463679: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-29 13:28:41.667729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-05-29 13:28:41.667772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-05-29 13:28:41.667782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-05-29 13:28:41.670562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:c4:00.0, compute capability: 7.5)
2021-05-29 13:28:43.650260: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-05-29 13:28:43.650711: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2499965000 Hz
2021-05-29 13:28:48.349778: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-29 13:28:48.722834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-29 13:28:48.811569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-05-29 13:29:00.133751: E tensorflow/stream_executor/dnn.cc:616] CUDNN_STATUS_EXECUTION_FAILED
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1972): 'cudnnRNNBackwardData( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, output_desc.handles(), output_data.opaque(), output_desc.handles(), output_backprop_data.opaque(), output_h_desc.handle(), output_h_backprop_data.opaque(), output_c_desc.handle(), output_c_backprop_data.opaque(), rnn_desc.params_handle(), params.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), input_desc.handles(), input_backprop_data->opaque(), input_h_desc.handle(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_backprop_data->opaque(), workspace.opaque(), workspace.size(), reserve_space_data->opaque(), reserve_space_data->size())'
2021-05-29 13:29:00.133818: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cudnn_rnn_ops.cc:1926 : Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 128, 64, 1, 401, 64, 64] 
Traceback (most recent call last):
  File "lstm_model.py", line 77, in <module>
    callbacks=[WandbCallback()], batch_size=BATCH_SIZE, epochs=EPOCHS)
  File "/scratch/users/ramyar/cs230/cs230_venv/lib/python3.6/site-packages/wandb/integration/keras/keras.py", line 124, in new_v2
    return old_v2(*args, **kwargs)
  File "/share/software/user/open/py-tensorflow/2.4.1_py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File "/share/software/user/open/py-tensorflow/2.4.1_py36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 828, in __call__
    result = self._call(*args, **kwds)
  File "/share/software/user/open/py-tensorflow/2.4.1_py36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 888, in _call
    return self._stateless_fn(*args, **kwds)
  File "/share/software/user/open/py-tensorflow/2.4.1_py36/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 2943, in __call__
    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
  File "/share/software/user/open/py-tensorflow/2.4.1_py36/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1919, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/share/software/user/open/py-tensorflow/2.4.1_py36/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 560, in call
    ctx=ctx)
  File "/share/software/user/open/py-tensorflow/2.4.1_py36/lib/python3.6/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InternalError:    Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 128, 64, 1, 401, 64, 64] 
	 [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]
	 [[Adam/gradients/PartitionedCall]] [Op:__inference_train_function_11645]

Function call stack:
train_function -> train_function -> train_function

wandb: Waiting for W&B process to finish, PID 83857
wandb: Program failed with code 1.  Press ctrl-c to abort syncing.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /scratch/users/ramyar/cs230/cs230_project/code/wandb/run-20210529_132832-12j70w8e/logs/debug.log
wandb: Find internal logs for this run at: /scratch/users/ramyar/cs230/cs230_project/code/wandb/run-20210529_132832-12j70w8e/logs/debug-internal.log
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced cerulean-bush-5: https://wandb.ai/ramyarangan/splicing/runs/12j70w8e
/var/spool/slurmd/job25415477/slurm_script: line 46: deactivate: command not found
